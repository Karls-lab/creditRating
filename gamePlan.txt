Preprocessing! 
There's a ton of data! What features are most important? 

TODO LIST: 
    - Select some features, and apply some preprocessing to them.

    - Create a preprocessing python script for each feature 

    - For each feature, explain what that feature is, and why it's important.
    


DATA INSIGHTS:
    Some rows have 'depth level' so people have past applications. 
    When we merge this without accounting for this, it may cause issues such 
    as duplicate rows.

    



MODEL THINGS:
    - 'Minimum redundancy maximum relevance' (mRMR) to select the most important features.
    - l2 regularization to prevent overfitting.
    - k-fold cross validation to test the model.
    - Grid search to find the best hyperparameters.
    - Learning Rate decay function 
    - Early stopping to prevent overfitting.
    - Dropout to prevent overfitting.
    - Batch normalization to prevent overfitting.

Questions:
    - Data augmentation?
    - Predefined Model (Xception)
    - RNN? 
