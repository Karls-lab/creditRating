{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from processMain import processMain\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df columns in process Main: Index(['case_id', 'district_544M', 'mainoccupationinc_437A',\n",
      "       'cancelreason_3545846M', 'annuity_853A', 'credamount_590A'],\n",
      "      dtype='object')\n",
      "len of columns: 19\n",
      "len of final training col: 456\n",
      "Len of missing: 442\n",
      "len of unexpected: ['mainoccupationinc_437A_0.0', 'case_id', 'cancelreason_3545846M_0', 'mainoccupationinc_437A_200000.0', 'district_544M_0']\n",
      "target in df: False\n",
      "len of columns after adding missing: 455\n"
     ]
    }
   ],
   "source": [
    "file_path = '../data/home-credit-credit-risk-model-stability/csv_files/test'\n",
    "\n",
    "# open test_base.csv\n",
    "# open test_appleprev_1_0.csv\n",
    "\n",
    "df_base = pd.read_csv(file_path + '/test_base.csv')\n",
    "df_appleprev_1_0 = pd.read_csv(file_path + '/test_applprev_1_0.csv')\n",
    "df_person_1 = pd.read_csv(file_path + '/test_person_1.csv')\n",
    "df_person_2 = pd.read_csv(file_path + '/test_person_2.csv')\n",
    "df = pd.merge(df_base, df_appleprev_1_0, on='case_id', how='left')\n",
    "df = pd.merge(df, df_person_1, on='case_id', how='left')\n",
    "df = pd.merge(df, df_person_2, on='case_id', how='left')\n",
    "\n",
    "\n",
    "df = processMain(df, keep_col=['case_id'])\n",
    "\n",
    "# Now concat my test with my train to get the right columns\n",
    "df_train = pd.read_csv(\"../data/mergedDatasets/person&Applprev.csv\")\n",
    "\n",
    "df_final = pd.read_csv('../data/processed/final.csv')\n",
    "missing_columns = list(set(df_final.columns) - set(df.columns))\n",
    "\n",
    "print(f'len of columns: {len(df.columns)}')\n",
    "print(f'len of final training col: {len(df_final.columns)}')\n",
    "print(f'Len of missing: {len(missing_columns)}')\n",
    "\n",
    "# display columsn that are in df but not in df_final\n",
    "unexpected_columns = list(set(df.columns) - set(df_final.columns))\n",
    "print(f'len of unexpected: {unexpected_columns}')\n",
    "\n",
    "# remove unexpected columns form df\n",
    "df = df.drop(unexpected_columns, axis=1)\n",
    "print(f'target in df: {\"target\" in df.columns}')\n",
    "\n",
    "default_values = pd.DataFrame(0, index=df.index, columns=missing_columns)\n",
    "df = pd.concat([df, default_values], axis=1)\n",
    "df = df.drop('target', axis=1)\n",
    "print(f'len of columns after adding missing: {len(df.columns)}')\n",
    "\n",
    "df.to_csv('../data/processed/test.csv', index=False)\n",
    "\n",
    "\n",
    "# # Calculate missing columns\n",
    "# missing_columns = list(set(df_final.columns) - set(df.columns))\n",
    "# # Calculate unexpected columns\n",
    "# unexpected_columns = list(set(df.columns) - set(df_final.columns))\n",
    "# # Display the results\n",
    "# print(\"Number of missing columns:\", len(missing_columns))\n",
    "# print(\"Missing columns:\", missing_columns)\n",
    "# print(\"Number of unexpected columns:\", len(unexpected_columns))\n",
    "# print(\"Unexpected columns:\", unexpected_columns)\n",
    "\n",
    "\n",
    "\n",
    "# Now add min missing columns (fill with 0's)\n",
    "# print(f'are columns equal: {df_final.columns == df.columns}')\n",
    "# print(f'columns of final: {df_final.columns}')\n",
    "# print(f'columsn of test: {df.columns}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[0.17570569]\n",
      " [0.19442187]\n",
      " [0.11452612]\n",
      " [0.09791911]\n",
      " [0.5506507 ]\n",
      " [0.5506507 ]\n",
      " [0.5506507 ]\n",
      " [0.2315045 ]\n",
      " [0.19276224]\n",
      " [0.5506507 ]]\n"
     ]
    }
   ],
   "source": [
    "# Now Load the model in and make predictions\n",
    "model = keras.models.load_model('../model/model.keras')\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(df)\n",
    "print(predictions)\n",
    "\n",
    "df = pd.read_csv('../data/home-credit-credit-risk-model-stability/csv_files/test/test_base.csv')\n",
    "df = df[['case_id']]\n",
    "df['score'] = predictions\n",
    "df.to_csv('../data/predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
