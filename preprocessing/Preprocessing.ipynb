{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas as pd\n",
    "import sys \n",
    "import os\n",
    "\n",
    "def downsample_majority_class(df, target_column, random_state=None):\n",
    "    \"\"\"\n",
    "    Downsample the majority class in a DataFrame with imbalanced classes.\n",
    "    \"\"\"\n",
    "    majority_class = df[df[target_column] == 0]\n",
    "    minority_class = df[df[target_column] == 1]\n",
    "    print(\"number of minority class: \", len(minority_class))\n",
    "    downsampled_majority = majority_class.sample(n=len(minority_class), random_state=random_state)\n",
    "    downsampled_df = pd.concat([downsampled_majority, minority_class], ignore_index=True)\n",
    "    return downsampled_df\n",
    "\n",
    "# smote = SMOTE(sampling_strategy={1: 50000})\n",
    "# X = df.drop(columns='RainTomorrow')\n",
    "# y = df['RainTomorrow']\n",
    "# X, y = smote.fit_resample(X, y)\n",
    "\n",
    "# # Apply random undersampling to the majority class (class 0)\n",
    "# undersampler = RandomUnderSampler(sampling_strategy='majority')\n",
    "# X_resampled, y_resampled = undersampler.fit_resample(X, y)\n",
    "\n",
    "# # Concatenate the downsampled data into a new DataFrame\n",
    "# df = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name='RainTomorrow')], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "\"\"\" Declare categorial and numerical features. Filter df down to these features and \n",
    "    case_id and target \n",
    "\"\"\"\n",
    "def processMain(df):\n",
    "    # Read in variables from features.csv, which contains the categorical and numerical features\n",
    "    f_df = pd.read_csv('features.csv')\n",
    "    cat_f = f_df[f_df['type'] == 'categorical']['name'].tolist()\n",
    "    num_f = f_df[f_df['type'] == 'numerical']['name'].tolist()\n",
    "    display(f\"categorical features: {cat_f}\")\n",
    "    display(f\"numerical features: {num_f}\")\n",
    "    col_to_keep = ['case_id', 'target'] + cat_f + num_f\n",
    "    df = df[col_to_keep]\n",
    "    print(f\"df columns: {df.columns}\")\n",
    "    df.to_csv('TEST0.csv', index=False)\n",
    "\n",
    "    # For categorical variables, take the most recent value\n",
    "    for col in cat_f:\n",
    "        for case_id in df['case_id'].unique():\n",
    "            common_val = df[df['case_id'] == case_id][col].value_counts().idxmax()\n",
    "            df.loc[df['case_id'] == case_id, col] = common_val\n",
    "            # print(f\"common_val: {common_val}\")\n",
    "\n",
    "    # For numerical variables, take the mean of the values\n",
    "    for col in num_f:\n",
    "        for case_id in df['case_id'].unique():\n",
    "            common_val = df[df['case_id'] == case_id][col].mean()\n",
    "            df.loc[df['case_id'] == case_id, col] = common_val\n",
    "\n",
    "    # round to 2 decimal places. Replace missing numerical values with the mean\n",
    "    df.loc[:, num_f] = df[num_f].round(2)\n",
    "    df.loc[:, num_f] = df[num_f].fillna(df[num_f].mean())\n",
    "\n",
    "    df.to_csv('TEST1.csv', index=False)\n",
    "\n",
    "    # Now for case_id's the data is aggregated, so now we can drop duplicates\n",
    "    df = df.drop_duplicates(subset='case_id')\n",
    "    df.to_csv('TEST2.csv', index=False)\n",
    "\n",
    "    # one-hot encode the categorical variables\n",
    "    df = pd.get_dummies(df, columns=cat_f, dtype=np.int8)\n",
    "\n",
    "    # standardize the continuous variables\n",
    "    scaler = StandardScaler()\n",
    "    df[num_f] = scaler.fit_transform(df[num_f]) \n",
    "\n",
    "    df.to_csv('cleansed_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"categorical features: ['district_544M', 'mainoccupationinc_437A', 'cancelreason_3545846M']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"numerical features: ['annuity_853A', 'credamount_590A']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df columns: Index(['case_id', 'target', 'district_544M', 'mainoccupationinc_437A',\n",
      "       'cancelreason_3545846M', 'annuity_853A', 'credamount_590A'],\n",
      "      dtype='object')\n",
      "\n",
      "Preprocessed dataframe info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59 entries, 0 to 58\n",
      "Columns: 101 entries, case_id to cancelreason_3545846M_a55475b1\n",
      "dtypes: float64(2), int64(99)\n",
      "memory usage: 46.7 KB\n",
      "target\n",
      "0    57\n",
      "1     2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(os.path.join(\"../\", \"data\", \"mergedDatasets\", \"person&Applprev.csv\"))\n",
    "\n",
    "# Figure out how to aggregate the data.\n",
    "# df = df.groupby('case_id').agg({'target': 'max', 'case_id': 'count'}).reset_index()\n",
    "# df.to_csv('TEST.csv', index=False)\n",
    "# sys.exit()\n",
    "# df = df.drop_duplicates(subset=['case_id'])\n",
    "\n",
    "\"\"\" Display the number of cases with target 1 and 0 \"\"\"\n",
    "# df = df[df['target'] == 1]\n",
    "# df.to_csv(os.path.join(rootPath, 'data', 'processed', 'target_1.csv'), index=False)\n",
    "\n",
    "processMain(df)\n",
    "p_df = pd.read_csv('cleansed_df.csv')\n",
    "# df = downsample_majority_class(df, 'target')\n",
    "print(f\"\\nPreprocessed dataframe info:\\n\")\n",
    "p_df.info()\n",
    "print(p_df['target'].value_counts())\n",
    "# df.to_csv(os.path.join(rootPath, 'data', 'processed', 'downsampled.csv'), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
